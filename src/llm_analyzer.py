import os
from openai import OpenAI
import logging
from dotenv import load_dotenv

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMAnalyzer:
    """Analisador de evid√™ncias usando GPT-4"""
    
    def __init__(self):
        load_dotenv()
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    def analyze_evidence(self, evidence_results):
        """
        Analisa os resultados das buscas multimodais e gera um relat√≥rio
        
        Args:
            evidence_results: Dict com resultados por modalidade
            {
                'vision': [...],
                'audio': [...],
                'text': [...],
                'depth': [...]
            }
        """
        # Formata as evid√™ncias para o prompt
        evidence_summary = self._format_evidence(evidence_results)
        
        prompt = f"""Voc√™ √© um detetive forense especializado em analisar evid√™ncias multimodais no caso do crime em Gotham City.

EVID√äNCIAS COLETADAS:
{evidence_summary}

Por favor, analise as evid√™ncias acima e forne√ßa:

1. PADR√ïES IDENTIFICADOS:
- Conex√µes entre diferentes tipos de evid√™ncia
- Padr√µes temporais ou espaciais relevantes
- Caracter√≠sticas distintivas do suspeito

2. SUSPEITO PROV√ÅVEL:
- Identidade do principal suspeito
- N√≠vel de confian√ßa na identifica√ß√£o (0-100%)
- Justificativa para a identifica√ß√£o

3. PR√ìXIMOS PASSOS:
- Recomenda√ß√µes para a investiga√ß√£o
- Evid√™ncias adicionais necess√°rias
- √Åreas que precisam de mais investiga√ß√£o

Formato o relat√≥rio de forma clara e profissional."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um detetive forense especializado em an√°lise de evid√™ncias multimodais."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            report = response.choices[0].message.content
            logger.info("\nüìã Relat√≥rio Forense Gerado:")
            logger.info("=" * 50)
            logger.info(report)
            logger.info("=" * 50)
            
            return report
            
        except Exception as e:
            logger.error(f"Erro ao gerar relat√≥rio: {str(e)}")
            return None
    
    def _format_evidence(self, evidence_results):
        """Formata as evid√™ncias para o prompt"""
        formatted = []
        
        for modality, results in evidence_results.items():
            formatted.append(f"\n{modality.upper()}:")
            for i, result in enumerate(results, 1):
                description = result.get('description', 'Sem descri√ß√£o')
                similarity = result.get('score', 0)
                formatted.append(f"{i}. {description} (Similaridade: {similarity:.2f})")
        
        return "\n".join(formatted)

    def analyze_cross_modal_connections(self, results_a, modality_a, results_b, modality_b):
        """Analisa conex√µes espec√≠ficas entre duas modalidades diferentes"""
        prompt = f"""Analise a rela√ß√£o entre as seguintes evid√™ncias de modalidades diferentes:

{modality_a.upper()}:
{self._format_evidence({modality_a: results_a})}

{modality_b.upper()}:
{self._format_evidence({modality_b: results_b})}

Por favor, identifique:
1. Conex√µes diretas entre as evid√™ncias
2. Padr√µes que sugerem o mesmo suspeito
3. Inconsist√™ncias ou contradi√ß√µes
4. For√ßa da correla√ß√£o (0-100%)"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4-turbo-preview",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um especialista em an√°lise forense de evid√™ncias multimodais."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            analysis = response.choices[0].message.content
            logger.info(f"\nüîç An√°lise Cross-Modal ({modality_a} x {modality_b}):")
            logger.info(analysis)
            
            return analysis
            
        except Exception as e:
            logger.error(f"Erro na an√°lise cross-modal: {str(e)}")
            return None